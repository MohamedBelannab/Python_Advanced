{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "   <h1>Probl√®me : Conception d'un syst√®me de pr√©diction de donn√©es avec Python avanc√© </h1>\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface `IModel`\n",
    "> L'interface IModel est une classe abstraite qui d√©finit deux m√©thodes principales que tout mod√®le de machine learning doit impl√©menter :\n",
    "- `train` : Pour entra√Æner le mod√®le avec des donn√©es d'entra√Ænement.\n",
    "- `predict` : Pour faire des pr√©dictions sur de nouvelles donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "class IModel(ABC):\n",
    "    @abstractmethod\n",
    "    #M√©thode d'entra√Ænement du mod√®le.\n",
    "    def train(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        pass\n",
    "    \n",
    "    #M√©thode de pr√©diction sur des donn√©es.\n",
    "    @abstractmethod\n",
    "    def predict(self, X: pd.DataFrame) -> List[float]:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©corateur `@log_decorator`\n",
    "> La fonction log_decorator est un d√©corateur Python qui permet de :\n",
    "- Enregistrer un message de log avant l'ex√©cution d'une fonction avec ses arguments.\n",
    "- Enregistrer un message de succ√®s si la fonction s'ex√©cute correctement.\n",
    "- Enregistrer un message d'erreur avec les d√©tails si une exception survient dans la fonction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configuration de base du logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', filename='system.log')\n",
    "\n",
    "def log_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            logging.info(f\"Running {func.__name__} with arguments {args} {kwargs}\")\n",
    "            result = func(*args, **kwargs)\n",
    "            logging.info(f\"{func.__name__} completed successfully.\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in {func.__name__}: {e}\")\n",
    "            raise e\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe `DataPipeline`\n",
    "> La classe DataPipeline g√®re le chargement, le pr√©traitement, et la division des donn√©es. Elle utilise un g√©n√©rateur pour parcourir les donn√©es ligne par ligne.\n",
    "- Attributs :\n",
    "    - `_filename` : Nom du fichier CSV contenant les donn√©es.\n",
    "    - `_data` : Donn√©es charg√©es sous forme de DataFrame de pandas.\n",
    "- M√©thodes :\n",
    "    - `load_data` : Charge les donn√©es depuis un fichier CSV.\n",
    "    - `preprocess_data` : Nettoie les donn√©es en supprimant les valeurs manquantes.\n",
    "    - `split_data` : Divise les donn√©es en ensembles d'entra√Ænement et de test.\n",
    "    - `data_generator` : G√©n√©rateur qui permet de parcourir les donn√©es ligne par ligne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from typing import Tuple, Generator\n",
    "\n",
    "class DataPipeline:\n",
    "    def __init__(self, filename: str):\n",
    "        self._filename = filename\n",
    "        self._data: pd.DataFrame = None\n",
    "\n",
    "    @property\n",
    "    #Getter pour les donn√©es.\n",
    "    def data(self) -> pd.DataFrame:\n",
    "        return self._data\n",
    "\n",
    "    @data.setter\n",
    "    #Setter pour les donn√©es.\n",
    "    def data(self, data: pd.DataFrame) -> None:\n",
    "        self._data = data\n",
    "\n",
    "    @log_decorator\n",
    "    #Charge les donn√©es depuis un fichier CSV.\n",
    "    def load_data(self) -> None:\n",
    "        self._data = pd.read_csv(self._filename)\n",
    "        print(f\"Donn√©es charg√©es depuis üòÑ {self._filename}\")\n",
    "\n",
    "    @log_decorator\n",
    "    def preprocess_data(self) -> None:\n",
    "        self._data = self._data.dropna(inplace=True)\n",
    "\n",
    "    @log_decorator\n",
    "    #Diviser les donn√©es en ensemble d'entra√Ænement et de test.\n",
    "    def split_data(self, test_size: float = 0.2) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "        X = self._data.drop('target', axis=1)\n",
    "        y = self._data['target']\n",
    "        return train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    #G√©n√©rateur pour parcourir les donn√©es.\n",
    "    def data_generator(self, batch_size: int) -> Generator[pd.DataFrame, None, None]:\n",
    "        for start in range(0, len(self._data), batch_size):\n",
    "            yield self._data.iloc[start:start + batch_size]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©corateur `@timing`\n",
    ">  Le d√©corateur @timing mesure et affiche le temps d'ex√©cution des m√©thodes qu'il d√©core. Il est utilis√© pour suivre la performance en temps r√©el.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timing(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Temps d'ex√©cution de {func.__name__}: {end_time - start_time:.4f} secondes\")\n",
    "        return result\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe `RandomForestModel`\n",
    "> Impl√©mente le mod√®le de Random Forest √† l'aide de l'interface IModel. Ce mod√®le utilise RandomForestClassifier de scikit-learn.\n",
    "- M√©thodes :\n",
    "    - `train` : Entra√Æne le mod√®le avec des donn√©es d'entra√Ænement.\n",
    "    - `predict` : Fait des pr√©dictions sur de nouvelles donn√©es.\n",
    "    - `evaluate` : Calcule la pr√©cision du mod√®le sur des donn√©es de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class RandomForestModel(IModel):\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestClassifier()\n",
    "\n",
    "    @log_decorator\n",
    "    @timing\n",
    "    #Entra√Æner le mod√®le RandomForest.\n",
    "    def train(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "    @log_decorator\n",
    "    @timing\n",
    "    #Pr√©diction avec le mod√®le RandomForest.\n",
    "    def predict(self, X: pd.DataFrame) -> List[float]:\n",
    "        return self.model.predict(X).tolist()\n",
    "\n",
    "    @log_decorator\n",
    "    #√âvaluer le mod√®le sur un ensemble de test.\n",
    "    def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> float:\n",
    "        y_pred = self.predict(X_test)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # √âvaluer le mod√®le sans sklearn accuracy_score.\n",
    "    # def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> float:\n",
    "    #     y_pred = self.predict(X_test)\n",
    "    #     correct = sum(y_test == y_pred)\n",
    "    #     return correct / len(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe `SVMModel`\n",
    "> Impl√©mente le mod√®le SVM en utilisant SVC de scikit-learn. Ce mod√®le impl√©mente √©galement l'interface IModel.\n",
    "- M√©thodes :\n",
    "    - `train` : Entra√Æne le mod√®le SVM.\n",
    "    - `predict` : Fait des pr√©dictions sur de nouvelles donn√©es.\n",
    "    - `evaluate` : Calcule la pr√©cision du mod√®le.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "class SVMModel(IModel):\n",
    "    def __init__(self):\n",
    "        self.model = SVC()\n",
    "\n",
    "    @log_decorator\n",
    "    @timing\n",
    "    #Entra√Æner le mod√®le SVM.\n",
    "    def train(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    @log_decorator\n",
    "    @timing\n",
    "    #Pr√©diction avec le mod√®le SVM.\n",
    "    def predict(self, X: pd.DataFrame) -> List[float]:\n",
    "        return self.model.predict(X).tolist()\n",
    "\n",
    "    #√âvaluer le mod√®le sur un ensemble de test.\n",
    "    def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> float:\n",
    "        y_pred = self.predict(X_test)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # √âvaluer le mod√®le sans sklearn accuracy_score.\n",
    "    # def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> float:\n",
    "    #     y_pred = self.predict(X_test)\n",
    "    #     correct = sum(y_test == y_pred)\n",
    "    #     return correct / len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es charg√©es depuis üòÑ data.csv\n",
      "\n",
      "RandomForestModel\n",
      "Temps d'ex√©cution de train: 0.1964 secondes\n",
      "Temps d'ex√©cution de predict: 0.0089 secondes\n",
      "\n",
      "SVMModel\n",
      "Temps d'ex√©cution de train: 0.0020 secondes\n",
      "Temps d'ex√©cution de predict: 0.0010 secondes\n",
      "\n",
      "Data Generator:\n",
      "   feature1  feature2  feature3  feature4  target\n",
      "0  0.374540  2.378596  1.068571  0.773856       1\n",
      "1  0.950714  0.405175  0.836367  0.046878       0\n",
      "2  0.731994  2.123425  0.599406  0.084544       0\n",
      "3  0.598658  0.299509  1.188251  0.991677       0\n",
      "4  0.156019  2.862336  0.296391  1.194115       1\n",
      "5  0.155995  1.220905  1.526876  0.953861       0\n",
      "6  0.058084  0.346888  0.354275  0.741358       1\n",
      "7  0.866176  0.173258  0.904170  1.169807       1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. Charger et pr√©traiter les donn√©es\n",
    "    pipeline = DataPipeline('data.csv')\n",
    "    pipeline.load_data()\n",
    "    pipeline.preprocess_data()\n",
    "    \n",
    "    # 2. Diviser les donn√©es\n",
    "    X_train, X_test, y_train, y_test = pipeline.split_data(test_size=0.2)\n",
    "    \n",
    "    # 3. Entra√Æner et √©valuer le mod√®le RandomForest\n",
    "    print(\"\\nRandomForestModel\")\n",
    "    rf_model = RandomForestModel()\n",
    "    rf_model.train(X_train, y_train)\n",
    "    rf_model.evaluate(X_test, y_test)\n",
    "    \n",
    "    # 4. Entra√Æner et √©valuer le mod√®le SVM\n",
    "    print(\"\\nSVMModel\")\n",
    "    svm_model = SVMModel()\n",
    "    svm_model.train(X_train, y_train)\n",
    "    svm_model.evaluate(X_test, y_test)\n",
    "    \n",
    "    # 7. Utiliser le g√©n√©rateur pour parcourir les donn√©es\n",
    "    print(\"\\nData Generator:\")\n",
    "    for row in pipeline.data_generator(batch_size=1000):\n",
    "        print(row)\n",
    "        break  #show the first row  üòé\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:\n",
    "\n",
    "1. **Donn√©es charg√©es depuis `data.csv`**:\n",
    "   - Les donn√©es ont √©t√© charg√©es avec succ√®s depuis le fichier `data.csv`.\n",
    "\n",
    "2. **RandomForestModel**:\n",
    "   - **Temps d'ex√©cution de `train`**: 0.1964 ondes  \n",
    "     Cela indique que la m√©thode `train` du mod√®le `RandomForestModel` a pris **0.1964condes** pour s'ex√©cuter.\n",
    "   - **Temps d'ex√©cution de `predict`**: 0.0089econdes  \n",
    "     Cela montre que la m√©thode `predict` du mod√®le `RandomForestModel` a pris **0.0089econdes** pour faire des pr√©dictions.\n",
    "\n",
    "3. **SVMModel**:\n",
    "   - **Temps d'ex√©cution de `train`**: 0.0020 secondes  \n",
    "     La m√©thode `train` du mod√®le `SVMModel` a pris **0.0020 secondes** pour s'ex√©cuter.\n",
    "   - **Temps d'ex√©cution de `predict`**: 0.0010 secondes  \n",
    "     La m√©thode `predict` du mod√®le `SVMModel` a pris **0.0010 secondes** pour faire des pr√©dictions.\n",
    "\n",
    "4. **Data Generator**:\n",
    "   - Le g√©n√©rateur de donn√©es a renvoy√© les premi√®res lignes des donn√©es suivantes :\n",
    "\n",
    "| feature1 | feature2 | feature3 | feature4 | target |\n",
    "|----------|----------|----------|----------|--------|\n",
    "| 0.374540 | 2.378596 | 1.068571 | 0.773856 | 1      |\n",
    "| 0.950714 | 0.405175 | 0.836367 | 0.046878 | 0      |\n",
    "| 0.731994 | 2.123425 | 0.599406 | 0.084544 | 0      |\n",
    "| 0.598658 | 0.299509 | 1.188251 | 0.991677 | 0      |\n",
    "| 0.156019 | 2.862336 | 0.296391 | 1.194115 | 1      |\n",
    "| 0.155995 | 1.220905 | 1.526876 | 0.953861 | 0      |\n",
    "| 0.058084 | 0.346888 | 0.354275 | 0.741358 | 1      |\n",
    "| 0.866176 | 0.173258 | 0.904170 | 1.169807 | 1      |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "   <h2>Mohamed BELANNAB </h2>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
